---
title: "Modelos Estructurales"
subtitle: "OKONOMETRIC CISE"
author: "William X. Ramos Chucuri"
date: "`r Sys.Date()`"  
format:
  html:
    toc: true
    toc-depth: 3
    code-fold: true
    number-sections: true
    output-file: "index"
  docx: default
  pdf:
    toc: true
    number-sections: true
    df-print: kable
lang: es
params:
  fecha_corte: "2024-12-31"
---

# **1. Modelos Estructurales**

-   Modelos estructurales vs Modelos Estad√≠sticos

-   La estimaci√≥n estructural tiene m√∫ltiples limitaciones.

-   El uso de modelos parsimoniosos tiene un costo, podemos caer el modelos sub-parametrizados, es decir podemos estimar modelos sesgados e inconsistentes. (Condiciones fundamentales en econometr√≠a).

-   La exogeneidad estricta es un supuesto muy restrictivo en un modelo multiecuacional.

-   Los modelos VAR son modelos estad√≠sticos.

    -   El poner restricciones al modelo (Matrices o condiciones- nos ayudar√≠an a transformarlo en un modelo estructural **SVAR.**

-   Los modelos de Equilibrio general son modelos estructurales \| Estos modelos me permiten modelar situaciones como la **pandemia COVID-19.**

    -   Permiten modelar situaciones sobre las cuales no tenemos historia, es decir una estructura consistente.

## 1.2.Modelo VAR(p)

Un modelo autorregresivo vectorial de orden ( p ), denotado como ( VAR(p) ), se define de la siguiente forma:

$X_t = c + A_1 X_{t-1} + A_2 X_{t-2} + \dots + A_p X_{t-p} + \varepsilon_t$

donde:

-   $X_t$ es un vector de variables end√≥genas de dimensi√≥n $K \times 1$.
-   $c$ es un vector de constantes de dimensi√≥n $K \times 1$.
-   $A_i$ son las matrices de coeficientes de dimensi√≥n $K \times K$ para cada rezago $i = 1, 2, \dots, p$.
-   $\varepsilon_t$ son los t√©rminos de error o innovaciones, con media cero y matriz de covarianza:

$\Sigma_u = E[\varepsilon_t \varepsilon_t']$

donde $\Sigma_u$ es sim√©trica y definida positiva.

En forma compacta, el modelo VAR(p) capta la interdependencia din√°mica entre las variables end√≥genas en el tiempo.

## 1.3. Propiedades B√°sicas

-   **Endogeneidad total:** todas las variables son explicadas por sus propios rezagos y los de las dem√°s.

-   **Identificaci√≥n reducida:** los residuos $Œµt$ pueden estar correlacionados, lo que impide inferencias estructurales.

-   **Necesidad de estacionariedad:** Las series deben ser integradas de orden 0 o cointegradas (en cuyo caso se usa VECM).

-   Hay que recordar que al ser integradas I (1) significa que tienen ra√≠z unitaria y son procesos no estacionarios. Si queremos trabajar en modelos multiecuacionales debemos quitar esta ra√≠z unitaria; por eso mencionamos que necesitamos que estas series sean procesos estacionarios.

-   Es decir que su media y varianza esten mas o menos alrededor de cero y constantes en el tiempo.

## 1.4. Proceso de estimaci√≥n

Cada ecuaci√≥n del VAR se estima por M√≠nimos Cuadrados Ordinarios (OLS), dado que los regresores son id√©nticos entre ecuaciones y se espera que el sistema no presente endogeneidad contempor√°nea.

El VAR describe la **din√°mica conjunta de las series** y permite an√°lisis como:

-   impulso-respuesta (IRF)- Una aproximaci√≥n estructural

-   descomposici√≥n de varianza (FEVD),

-   pron√≥sticos conjuntos.

## 1.5. El problema de identificaci√≥n

Un VAR reducido no permite identificar los efectos contempor√°neos ni distinguir causalidad estructural.

## 1.6. Identificaci√≥n en un modelo VAR estructural

Un VAR con ( n ) variables contiene:

$2n^2$

par√°metros en las matrices ( A ) y ( B ).

La matriz de covarianza de los errores, denotada como $\Sigma_u$, solo aporta:

$\frac{n(n + 1)}{2}$

ecuaciones independientes.

Por lo tanto, para lograr la identificaci√≥n del modelo, se requieren al menos:

$\frac{n(n - 1)}{2}$

restricciones adicionales, que generalmente se imponen sobre las matrices ( A ) o ( B ) (dependiendo del tipo de identificaci√≥n: contempor√°nea, de largo plazo, o basada en restricciones de signo).

En un modelo VAR estructural (SVAR), el objetivo es recuperar las relaciones estructurales contempor√°neas entre las variables, es decir, c√≥mo los choques estructurales (innovaciones puras) afectan simult√°neamente a las variables del sistema.

Sin embargo, el modelo estimado directamente (el VAR reducido) solo nos proporciona informaci√≥n sobre la **covarianza observada de los errores**, $\Sigma_u$.\
Esta matriz tiene $n(n + 1)/2$ elementos √∫nicos, ya que es **sim√©trica**.

El problema surge porque las matrices ( A ) y ( B ) contienen en total ( 2n\^2 ) par√°metros desconocidos, mientras que solo contamos con $n(n + 1)/2$ ecuaciones provenientes de $Sigma_u$.\
Esto implica que el sistema est√° **subidentificado**: hay m√°s par√°metros desconocidos que ecuaciones disponibles.

Para resolver este problema, se deben imponer **restricciones adicionales** que permitan identificar cada par√°metro estructural.\
En concreto, se necesitan al menos:

$\frac{n(n - 1)}{2}$

restricciones adicionales para que el n√∫mero de ecuaciones iguale al n√∫mero de par√°metros y el sistema quede **justamente identificado**.

------------------------------------------------------------------------

### üß© Tipos de restricciones comunes

1.  **Restricciones contempor√°neas (modelo tipo AB o recursivo - Cholesky):**\
    Se impone una estructura triangular en ( A ) o ( B ) asumiendo que ciertas variables no responden contempor√°neamente a otras.

2.  **Restricciones de largo plazo (modelo tipo Blanchard-Quah):**\
    Se imponen condiciones sobre la respuesta acumulada a los choques, por ejemplo, que ciertos choques no afectan permanentemente algunas variables.

3.  **Restricciones de signo (modelo de Uhlig):**\
    En lugar de ceros, se imponen signos (+/‚Äì) sobre las respuestas o sobre los impactos contempor√°neos.

------------------------------------------------------------------------

### üß† Ejemplo ilustrativo

Para un VAR de **2 variables (n = 2)**:

-   Par√°metros totales: $2n^2 = 8$
-   Ecuaciones de la covarianza: $n(n + 1)/2 = 3$
-   Restricciones necesarias: $n(n - 1)/2 = 1$

Por tanto, se necesita **al menos una restricci√≥n adicional** (por ejemplo, asumir que una variable no reacciona contempor√°neamente a otra) para lograr la identificaci√≥n.

------------------------------------------------------------------------

üí° **Conclusi√≥n:**

-   La identificaci√≥n en los modelos VAR estructurales es esencial para poder interpretar los choques estimados como ‚Äúcausales‚Äù o ‚Äúestructurales‚Äù.

-   Sin restricciones suficientes, solo observamos correlaciones reducidas, no relaciones estructurales.

**Ejemplo emp√≠co**

```{r}
# =========================================================
# 0) Paquetes y setup
# =========================================================
# install.packages(c("zoo","ggplot2","tseries","vars","urca","forecast","dplyr","tidyr"))
library(zoo)
library(ggplot2)
library(tseries)
library(vars)
library(urca)
library(forecast)
library(dplyr)
library(tidyr)

set.seed(42)

# =========================================================
# 1) Calendario y variables (72 trimestres 2007Q1‚Äì2024Q4)
# =========================================================
T  <- 72
fq <- 4
fechas <- as.yearqtr(seq(from = as.Date("2007-01-01"),
                         by = "quarter", length.out = T))
vars <- c("L_PP","L_PIB","L_GG","L_GC","L_GK","L_IF","L_IVA","L_ICE","L_IR")
k <- length(vars)

# =========================================================
# 2) DGP: I(1) con 2 relaciones de cointegraci√≥n plausibles
# =========================================================
# Œ≤ (columnas = vectores cointegrados)
beta <- matrix(0, nrow = k, ncol = 2, dimnames = list(vars, c("CI_gasto","CI_tributos")))
beta["L_GG","CI_gasto"] <- 1;   beta["L_GC","CI_gasto"] <- -0.7; beta["L_GK","CI_gasto"] <- -0.3
beta["L_IF","CI_tributos"] <- 1; beta["L_IVA","CI_tributos"] <- -0.5; beta["L_IR","CI_tributos"] <- -0.3; beta["L_ICE","CI_tributos"] <- -0.2

# Œ± (velocidades de ajuste)
alpha <- matrix(0, nrow = k, ncol = 2, dimnames = list(vars, c("CI_gasto","CI_tributos")))
alpha["L_GG","CI_gasto"]  <- -0.25
alpha["L_GC","CI_gasto"]  <- -0.10
alpha["L_GK","CI_gasto"]  <- -0.05
alpha["L_IF","CI_tributos"]  <- -0.20
alpha["L_IVA","CI_tributos"] <- -0.10
alpha["L_IR","CI_tributos"]  <- -0.08
alpha["L_ICE","CI_tributos"] <- -0.05
alpha["L_PIB","CI_gasto"]    <- -0.02
alpha["L_PIB","CI_tributos"] <- -0.01
alpha["L_PP",] <- c(0,0)  # petr√≥leo no corrige directamente

# Œì1 (din√°mica de corto plazo sobre ŒîY_{t-1})
Gamma1 <- matrix(0, nrow = k, ncol = k, dimnames = list(vars, vars))
Gamma1["L_PIB","L_PP"] <- 0.10
Gamma1["L_IF","L_PP"]  <- 0.08
Gamma1["L_IF","L_IVA"] <- 0.10; Gamma1["L_IF","L_IR"] <- 0.07; Gamma1["L_IF","L_ICE"] <- 0.05
Gamma1["L_GG","L_PIB"] <- 0.06
Gamma1["L_GC","L_GG"]  <- 0.10; Gamma1["L_GK","L_GG"] <- 0.06

# Œ£ (varianzas-covarianzas de shocks)
Sigma <- diag(c(0.20, 0.18, 0.15, 0.12, 0.12, 0.18, 0.15, 0.12, 0.12))
dimnames(Sigma) <- list(vars, vars)
Sigma["L_PIB","L_PP"] <- Sigma["L_PP","L_PIB"] <- 0.05
Sigma["L_IF","L_PP"]  <- Sigma["L_PP","L_IF"]  <- 0.04
Sigma["L_IF","L_IVA"] <- Sigma["L_IVA","L_IF"] <- 0.06
Sigma["L_GG","L_PIB"] <- Sigma["L_PIB","L_GG"] <- 0.04
Sigma <- (Sigma + t(Sigma))/2
C <- t(chol(Sigma))

# =========================================================
# 3) Simulaci√≥n VECM (ŒîY_t = Œì1 ŒîY_{t-1} + Œ± Œ≤' Y_{t-1} + Œµ_t)
# =========================================================
Y  <- matrix(0, nrow = k, ncol = T, dimnames = list(vars, NULL))
dY <- matrix(0, nrow = k, ncol = T, dimnames = list(vars, NULL))
Y[,1] <- c(4.6, 8.5, 9.2, 8.9, 7.8, 8.6, 7.9, 6.5, 7.6)

for (t in 2:T) {
  eps_t  <- C %*% rnorm(k)
  EC_lag <- t(beta) %*% Y[, t-1]           # (2x9)*(9x1) = (2x1)
  dY[,t] <- Gamma1 %*% dY[,t-1] + alpha %*% EC_lag + eps_t
  Y[,t]  <- Y[,t-1] + dY[,t]
}

```

**Series a modelar**

Identificaci√≥n econ√≥mica que usar√© (aj√∫stala si quieres):

-   **Petr√≥leo (L_PP)** es ‚Äúex√≥geno contempor√°neo‚Äù: no recibe shocks contempor√°neos de otras variables (solo su propio shock).

-   

-   **PIB (L_PIB)** puede reaccionar contempor√°neamente a **petr√≥leo**.

-   

-   **Gasto total (L_GG)** reacciona contempor√°neamente al **PIB** (reglas/prociclicidad).

-   

-   **Gasto corriente / de capital (L_GC, L_GK)** reaccionan a **G_G**.

-   

-   **Ingresos (L_IF)** reaccionan a **petr√≥leo** (v√≠a actividad/sector petrolero) y a **impuestos indirectos** (**L_IVA, L_IR, L_ICE**).

-   

-   Para el resto, dejamos par√°metros ‚Äúlibres‚Äù (NA) solo donde tiene sentido; el resto se fijan en 0.

```{r}
Y_ts <- ts(t(Y), start = c(2007,1), frequency = fq); colnames(Y_ts) <- vars
base_wide <- data.frame(
  fecha_q = fechas,
  year    = as.integer(format(fechas, "%Y")),
  quarter = as.integer(cycle(Y_ts)),
  as.data.frame(Y_ts),
  check.names = FALSE
)

base_long <- base_wide |>
  pivot_longer(cols = all_of(vars), names_to = "variable", values_to = "valor")

ggplot(base_long, aes(x = fecha_q, y = valor)) +
  geom_line() + facet_wrap(~ variable, scales = "free_y", ncol = 3) +
  labs(title = "Series simuladas (log)", x = NULL, y = "log") +
  theme_minimal()
```

**Estacionariedad en niveles y en diferencias**

```{r}
adf_levels <- sapply(vars, function(v) adf.test(Y_ts[,v])$p.value)
adf_diffs  <- sapply(vars, function(v) adf.test(diff(Y_ts[,v])[-1])$p.value)
cat("\nADF p-valores en niveles:\n"); print(round(adf_levels,4))
cat("\nADF p-valores en diferencias:\n"); print(round(adf_diffs,4))
```

## üìò **1Ô∏è‚É£ Hip√≥tesis del test ADF**

-   **H‚ÇÄ (nula):** La serie tiene una ra√≠z unitaria ‚Üí no estacionaria.

-   **H‚ÇÅ (alternativa):** La serie es estacionaria.

## üìä **2Ô∏è‚É£ Resultados por niveles**

| Variable | p-valor | Interpretaci√≥n                     |
|----------|---------|------------------------------------|
| L_PP     | 0.5077  | No se rechaza H‚ÇÄ ‚Üí no estacionaria |
| L_PIB    | 0.4831  | No estacionaria                    |
| L_GG     | 0.1429  | No estacionaria                    |
| L_GC     | 0.2622  | No estacionaria                    |
| L_GK     | 0.8133  | No estacionaria                    |
| L_IF     | 0.3314  | No estacionaria                    |
| L_IVA    | 0.1580  | No estacionaria                    |
| L_ICE    | 0.6756  | No estacionaria                    |
| L_IR     | 0.1775  | No estacionaria                    |

üîπ **Conclusi√≥n en niveles:**\
Todas las variables tienen p-valores \> 0.05 ‚Üí **no se rechaza la hip√≥tesis nula de ra√≠z unitaria**.\
‚û°Ô∏è **Ninguna serie es estacionaria en niveles.**

## üìà **3Ô∏è‚É£ Resultados en primeras diferencias**

| Variable | p-valor | Interpretaci√≥n                    |
|----------|---------|-----------------------------------|
| L_PP     | 0.0302  | Estacionaria                      |
| L_PIB    | 0.0100  | Estacionaria                      |
| L_GG     | 0.0100  | Estacionaria                      |
| L_GC     | 0.0162  | Estacionaria                      |
| L_GK     | 0.1010  | No estacionaria al 5% (pero casi) |
| L_IF     | 0.1381  | No estacionaria                   |
| L_IVA    | 0.1824  | No estacionaria                   |
| L_ICE    | 0.0965  | No estacionaria (marginal al 10%) |
| L_IR     | 0.0104  | Estacionaria                      |

üîπ **Conclusi√≥n en diferencias:**\
La mayor√≠a de las series

(L_PP, L_PIB, L_GG, L_GC, L_IR)

Son estacionarias en primeras diferencias (p \< 0.05).\
Algunas (L_GK, L_IF, L_IVA, L_ICE) presentan p-valores entre 0.09‚Äì0.18, lo que podr√≠a considerarse estacionarias al 10% o requerir una segunda diferencia o un ajuste de rezagos.

## **4Ô∏è‚É£ Implicaci√≥n para el modelo VAR**

-   Dado que las series no son estacionarias en niveles pero s√≠ lo son en diferencias, se clasifican como I(1) (integradas de orden uno).

-   Esto sugiere que podr√≠a existir cointegraci√≥n entre ellas, por lo cual el paso siguiente ser√≠a aplicar el test de Johansen:

**Seleccionamos los rezagos en niveles (para el Test de Johansen)**

```{r}

sel_lvl <- VARselect(Y_ts, lag.max = 4, type = "const")
cat("\nCriterios de informaci√≥n (niveles):\n"); print(sel_lvl$criteria)
p_opt <- as.integer(sel_lvl$selection["AIC(n)"])
Kj <- max(2, p_opt)
cat("\nUsando K =", Kj, "para Johansen.\n")

j_tr  <- ca.jo(Y_ts, type = "trace", K = Kj, ecdet = "const", spec = "transitory")
j_eig <- ca.jo(Y_ts, type = "eigen", K = Kj, ecdet = "const", spec = "transitory")
cat("\n--- Johansen TRACE ---\n"); print(summary(j_tr))
cat("\n--- Johansen EIGEN ---\n"); print(summary(j_eig))

choose_r_trace <- function(jobj, alpha = 0.05) {
  ts <- jobj@teststat
  cv <- jobj@cval[,"5pct"]
  sum(ts > cv)
}
r <- max(1, choose_r_trace(j_tr, 0.05))   # asegura r‚â•1 para poder estimar VECM
cat("\nRango de cointegraci√≥n estimado (trace, 5%): r =", r, "\n")

```

La salida proviene de la selecci√≥n del n√∫mero √≥ptimo de rezagos $(p)$ en un modelo VAR.\

Los criterios de informaci√≥n (AIC, HQ, SC, FPE) comparan la bondad de ajuste y la penalizaci√≥n por complejidad del modelo (n√∫mero de rezagos).

El objetivo es elegir el valor de $(p)$ que minimiza el criterio seleccionado.

-Normalmente **AIC** (Akaike Information Criterion) o **BIC/SC** (Schwarz Criterion).

```{r}
vecm_fit <- cajorls(j_tr, r = r)
cat("\n--- Beta (vectores cointegrados estimados) ---\n")
print(vecm_fit$beta)

var_from_vecm <- vec2var(j_tr, r = r)  
```

Funci√≥n para elejir r 5%

```{r}

cat("\n--- Portmanteau ---\n"); print(serial.test(var_from_vecm, lags.pt = 12, type = "PT.asymptotic"))
cat("\n--- ARCH ---\n"); print(arch.test(var_from_vecm, lags.multi = 5))
cat("\n--- Normalidad ---\n"); print(normality.test(var_from_vecm))
```

**Estimaci√≥n Estabilidad**

```{r}
var_levels <- VAR(Y_ts, p = Kj, type = "const")
mod_roots <- roots(var_levels, modulus = TRUE)
cat("\nM√≥dulos de autovalores (VAR en niveles, p=Kj):\n"); print(round(sort(mod_roots, decreasing = TRUE), 4))
plot(roots(var_levels))   # puntos dentro del c√≠rculo => estable

```

## VAR equivalente del VECM (para IRF/FEVD/forecast)

```{r}
dY_ts <- na.omit(diff(Y_ts))
sel_d <- VARselect(dY_ts, lag.max = 4, type = "const")
p_d <- ifelse(is.na(as.integer(sel_d$selection["AIC(n)"])), 2L, as.integer(sel_d$selection["AIC(n)"]))
cat("\nVAR(Œî) seleccionado (AIC): p_d =", p_d, "\n")
var_d <- VAR(dY_ts, p = p_d, type = "const")
stb_diff <- stability(var_d, type = "OLS-CUSUM")

```

```{r}
png("stability_VAR_diff_CUSUM.png", width = 1400, height = 900, res = 150)
par(mar = c(4, 4, 2, 1))
plot(stb_diff)
dev.off()
cat("Gr√°fico guardado en: stability_VAR_diff_CUSUM.png\n")
```

**IRF**

```{r}

irf_pp_pib <- irf(var_from_vecm, impulse = "L_PP", response = "L_PIB",
                  n.ahead = 12, boot = TRUE, ci = 0.95)
plot(irf_pp_pib)

fevd_v <- fevd(var_from_vecm, n.ahead = 12)


# Cierra cualquier gr√°fico abierto
while (!is.null(dev.list())) dev.off()

# Exporta el FEVD a un PNG
png("FEVD_VECM.png", width = 1400, height = 900, res = 150)
par(mar = c(4,4,2,1))  # M√°rgenes reducidas
plot(fevd_v)
dev.off()

cat("‚úÖ Gr√°fico FEVD guardado como 'FEVD_VECM.png' en tu directorio de trabajo.\n")


```

```{r}
# IRF: L_PP ‚Üí L_PIB
png("IRF_L_PP_to_L_PIB.png", width = 1400, height = 900, res = 150)
par(mar = c(4,4,2,1))
plot(irf_pp_pib)
dev.off()

cat("‚úÖ Gr√°fico IRF guardado como 'IRF_L_PP_to_L_PIB.png'\n")

```

## **Modelo SVAR**

```{r}
# =========================================================
# 0) Paquetes y setup
# =========================================================
# install.packages(c("zoo","ggplot2","tseries","vars","urca","forecast","dplyr","tidyr"))
library(zoo)
library(ggplot2)
library(tseries)
library(vars)
library(urca)
library(forecast)
library(dplyr)
library(tidyr)

set.seed(42)

# =========================================================
# 1) Calendario y variables (72 trimestres 2007Q1‚Äì2024Q4)
# =========================================================
T  <- 72
fq <- 4
fechas <- as.yearqtr(seq(from = as.Date("2007-01-01"),
                         by = "quarter", length.out = T))
vars <- c("L_PP","L_PIB","L_GG","L_GC","L_GK","L_IF","L_IVA","L_ICE","L_IR")
k <- length(vars)

# =========================================================
# 2) DGP: I(1) con 2 cointegraciones plausibles (para simular)
# =========================================================
beta <- matrix(0, nrow = k, ncol = 2, dimnames = list(vars, c("CI_gasto","CI_tributos")))
beta["L_GG","CI_gasto"] <- 1;   beta["L_GC","CI_gasto"] <- -0.7; beta["L_GK","CI_gasto"] <- -0.3
beta["L_IF","CI_tributos"] <- 1; beta["L_IVA","CI_tributos"] <- -0.5; beta["L_IR","CI_tributos"] <- -0.3; beta["L_ICE","CI_tributos"] <- -0.2

alpha <- matrix(0, nrow = k, ncol = 2, dimnames = list(vars, c("CI_gasto","CI_tributos")))
alpha["L_GG","CI_gasto"]  <- -0.25
alpha["L_GC","CI_gasto"]  <- -0.10
alpha["L_GK","CI_gasto"]  <- -0.05
alpha["L_IF","CI_tributos"]  <- -0.20
alpha["L_IVA","CI_tributos"] <- -0.10
alpha["L_IR","CI_tributos"]  <- -0.08
alpha["L_ICE","CI_tributos"] <- -0.05
alpha["L_PIB","CI_gasto"]    <- -0.02
alpha["L_PIB","CI_tributos"] <- -0.01
alpha["L_PP",] <- c(0,0)  # petr√≥leo no corrige directamente

Gamma1 <- matrix(0, nrow = k, ncol = k, dimnames = list(vars, vars))
Gamma1["L_PIB","L_PP"] <- 0.10
Gamma1["L_IF","L_PP"]  <- 0.08
Gamma1["L_IF","L_IVA"] <- 0.10; Gamma1["L_IF","L_IR"] <- 0.07; Gamma1["L_IF","L_ICE"] <- 0.05
Gamma1["L_GG","L_PIB"] <- 0.06
Gamma1["L_GC","L_GG"]  <- 0.10
Gamma1["L_GK","L_GG"]  <- 0.06

Sigma <- diag(c(0.20, 0.18, 0.15, 0.12, 0.12, 0.18, 0.15, 0.12, 0.12))
dimnames(Sigma) <- list(vars, vars)
Sigma["L_PIB","L_PP"] <- Sigma["L_PP","L_PIB"] <- 0.05
Sigma["L_IF","L_PP"]  <- Sigma["L_PP","L_IF"]  <- 0.04
Sigma["L_IF","L_IVA"] <- Sigma["L_IVA","L_IF"] <- 0.06
Sigma["L_GG","L_PIB"] <- Sigma["L_PIB","L_GG"] <- 0.04
Sigma <- (Sigma + t(Sigma))/2
C <- t(chol(Sigma))

# =========================================================
# 3) Simulaci√≥n VECM (ŒîY_t = Œì1 ŒîY_{t-1} + Œ± Œ≤' Y_{t-1} + Œµ_t)
# =========================================================
Y  <- matrix(0, nrow = k, ncol = T, dimnames = list(vars, NULL))
dY <- matrix(0, nrow = k, ncol = T, dimnames = list(vars, NULL))
Y[,1] <- c(4.6, 8.5, 9.2, 8.9, 7.8, 8.6, 7.9, 6.5, 7.6)

for (t in 2:T) {
  eps_t  <- C %*% rnorm(k)
  EC_lag <- t(beta) %*% Y[, t-1]           # (2x9)*(9x1) = (2x1)
  dY[,t] <- Gamma1 %*% dY[,t-1] + alpha %*% EC_lag + eps_t
  Y[,t]  <- Y[,t-1] + dY[,t]
}

Y_ts <- ts(t(Y), start = c(2007,1), frequency = fq); colnames(Y_ts) <- vars


```

```{r}
dY_ts <- na.omit(diff(Y_ts))
sel_d <- VARselect(dY_ts, lag.max = 4, type = "const")
p_d <- ifelse(is.na(as.integer(sel_d$selection["AIC(n)"])), 2L, as.integer(sel_d$selection["AIC(n)"]))
cat("Rezagos VAR(Œî) (AIC): p_d =", p_d, "\n")

var_d <- VAR(dY_ts, p = p_d, type = "const")   # <- 'varest'
cat("\nResumen VAR(Œî):\n"); print(summary(var_d))

# Diagn√≥sticos r√°pidos
cat("\nPortmanteau (autocorrelaci√≥n):\n"); print(serial.test(var_d, lags.pt = 12, type = "PT.asymptotic"))
cat("\nARCH (heterocedasticidad):\n");     print(arch.test(var_d, lags.multi = 5))
cat("\nNormalidad (Jarque-Bera multivariante):\n"); print(normality.test(var_d))

# Estabilidad (ra√≠ces del VAR(Œî))
mod_roots <- roots(var_d, modulus = TRUE)
cat("\nM√≥dulos de autovalores (VAR(Œî)):\n"); print(round(sort(mod_roots, decreasing = TRUE), 4))


```

```{r}
vnames_d <- colnames(var_d$y)
K <- length(vnames_d)

# A: 1 en diagonal; 0 = cero fijo; NA = libre
Amat_d <- diag(1, K); dimnames(Amat_d) <- list(vnames_d, vnames_d)

# ŒîL_PP (shock de petr√≥leo) NO recibe contempor√°neos del resto:
Amat_d["L_PP", setdiff(vnames_d, "L_PP")] <- 0

# Canales contempor√°neos plausibles (libres)
Amat_d["L_PIB","L_PP"] <- NA      # petr√≥leo ‚Üí PIB
Amat_d["L_GG","L_PIB"] <- NA      # PIB ‚Üí gasto total
Amat_d["L_GC","L_GG"]  <- NA      # gasto total ‚Üí gasto corriente
Amat_d["L_GK","L_GG"]  <- NA      # gasto total ‚Üí gasto capital
Amat_d["L_IF","L_PP"]  <- NA      # petr√≥leo ‚Üí ingresos fiscales
Amat_d["L_IF","L_IVA"] <- NA      # IVA ‚Üí ingresos fiscales
Amat_d["L_IF","L_IR"]  <- NA      # IR ‚Üí ingresos fiscales
Amat_d["L_IF","L_ICE"] <- NA      # ICE ‚Üí ingresos fiscales
# (todo lo no especificado queda en 0; ajusta NA/0 seg√∫n tu narrativa)

# B: diagonal (NA para las sd de los shocks), 0 fuera
Bmat_d <- diag(NA, K); dimnames(Bmat_d) <- list(vnames_d, vnames_d)
Bmat_d[row(Bmat_d) != col(Bmat_d)] <- 0

# Estimar SVAR(Œî)
svar_d <- SVAR(var_d, Amat = Amat_d, Bmat = Bmat_d, estmethod = "direct")
cat("\nSVAR(Œî) estimado con √©xito.\n")

```

```{r}
while (!is.null(dev.list())) dev.off()

# IRF: shock petr√≥leo ‚Üí PIB
irf_pp_pib_d <- irf(svar_d, impulse = "L_PP", response = "L_PIB",
                    n.ahead = 12, boot = TRUE, ci = 0.95)
png("IRF_SVAR_DIFF_LPP_to_LPIB.png", width = 1400, height = 900, res = 150)
par(mar = c(4,4,2,1)); plot(irf_pp_pib_d); dev.off()
cat("‚úÖ Guardado: IRF_SVAR_DIFF_LPP_to_LPIB.png\n")

# IRF: shock petr√≥leo ‚Üí ingresos fiscales
irf_pp_if_d <- irf(svar_d, impulse = "L_PP", response = "L_IF",
                   n.ahead = 12, boot = TRUE, ci = 0.95)
png("IRF_SVAR_DIFF_LPP_to_LIF.png", width = 1400, height = 900, res = 150)
par(mar = c(4,4,2,1)); plot(irf_pp_if_d); dev.off()
cat("‚úÖ Guardado: IRF_SVAR_DIFF_LPP_to_LIF.png\n")

# FEVD (12 pasos)
fevd_d <- fevd(svar_d, n.ahead = 12)
png("FEVD_SVAR_DIFF_12.png", width = 1400, height = 900, res = 150)
par(mar = c(4,4,2,1)); plot(fevd_d); dev.off()
cat("‚úÖ Guardado: FEVD_SVAR_DIFF_12.png\n")

# IRFs de petr√≥leo hacia todas las respuestas (lote)
responses <- c("L_PIB","L_GG","L_GC","L_GK","L_IF","L_IVA","L_ICE","L_IR")
for (resp in responses) {
  f <- irf(svar_d, impulse = "L_PP", response = resp, n.ahead = 12, boot = TRUE, ci = 0.95)
  fn <- paste0("IRF_SVAR_DIFF_LPP_to_", resp, ".png")
  png(fn, width = 1400, height = 900, res = 150)
  par(mar = c(4,4,2,1)); plot(f); dev.off()
  cat("‚úÖ Guardado: ", fn, "\n", sep = "")
}

cat("\n=== FIN: SVAR en diferencias (estacionario) con gr√°ficos exportados ===\n")
```

Forecast

```{r}
# ===============================
# FORECAST con VAR en diferencias
# ===============================

# Horizonte de pron√≥stico (trimestres)
h <- 8  # 2 a√±os

# 1) Pron√≥stico de diferencias (Œîlog) con el VAR estacionario
fc_d <- predict(var_d, n.ahead = h, ci = 0.95)

# Extraer medias, l√≠mites inferior/superior por variable
vnames_d <- colnames(var_d$y)
dhat_mean <- sapply(vnames_d, function(v) fc_d$fcst[[v]][, "fcst"])
dhat_low  <- sapply(vnames_d, function(v) fc_d$fcst[[v]][, "lower"])
dhat_high <- sapply(vnames_d, function(v) fc_d$fcst[[v]][, "upper"])

# 2) Reconstruir niveles (logs) desde el √∫ltimo dato observado
last_level <- as.numeric(tail(Y_ts, 1))   # vector de 9 niveles (logs) en 2024Q4
names(last_level) <- colnames(Y_ts)

# Funci√≥n auxiliar: acumula difs para pasar a niveles
rebuild_levels <- function(last_level, diffs_mat) {
  # diffs_mat: h x k (Œîlog pronosticadas)
  lev <- matrix(NA_real_, nrow = nrow(diffs_mat), ncol = ncol(diffs_mat))
  colnames(lev) <- colnames(diffs_mat)
  prev <- last_level
  for (t in 1:nrow(diffs_mat)) {
    lev[t, ] <- prev + diffs_mat[t, ]
    prev     <- lev[t, ]
  }
  lev
}

# Niveles pronosticados (punto), y bandas aprox. por acumulaci√≥n (did√°ctico)
lev_hat_mean <- rebuild_levels(last_level, dhat_mean)
lev_hat_low  <- rebuild_levels(last_level, dhat_low)
lev_hat_high <- rebuild_levels(last_level, dhat_high)

# 3) Construir fechas futuras (trimestres posteriores a 2024Q4)
#    Reusamos la secuencia "fechas" que ya tienes (2007Q1..2024Q4) y la extendemos
fechas_all <- as.yearqtr(seq(from = as.Date("2007-01-01"), by = "quarter", length.out = T + h))
fechas_fc  <- tail(fechas_all, h)  # fechas pron√≥stico

# 4) Armar data.frames para exportar a CSV
# a) Pron√≥stico en diferencias
fc_diff_df <- data.frame(
  fecha_q = fechas_fc,
  as.data.frame(dhat_mean),
  check.names = FALSE
)

# b) Pron√≥stico en niveles (logs)
fc_level_df <- data.frame(
  fecha_q = fechas_fc,
  as.data.frame(lev_hat_mean),
  check.names = FALSE
)

# 5) Exportar a CSV (carpeta de trabajo actual)
write.csv(fc_diff_df,  "forecast_VARdiff_deltas.csv", row.names = FALSE)
write.csv(fc_level_df, "forecast_VARdiff_levels.csv", row.names = FALSE)
cat("‚úÖ CSV guardados: forecast_VARdiff_deltas.csv, forecast_VARdiff_levels.csv\n")

# 6) Gr√°ficos exportados (hist√≥rico + pron√≥stico) para 4 variables clave
plot_series_fc <- function(varname, file_png) {
  # Serie hist√≥rica (niveles log)
  hist_ts <- Y_ts[, varname]
  # Serie pronosticada (niveles log)
  fc_ts <- ts(lev_hat_mean[, varname],
              start = c(2007 + (T)/4, (T %% 4) + 1),  # arranque inmediatamente despu√©s
              frequency = 4)

  # Cierra y abre dispositivo PNG grande para evitar m√°rgenes
  while (!is.null(dev.list())) dev.off()
  png(file_png, width = 1400, height = 900, res = 150)
  par(mar = c(4,4,2,1))
  # Gr√°fico base del hist√≥rico
  plot(hist_ts, type = "l", lwd = 2, xlab = "Trimestre", ylab = "Log(nivel)",
       main = paste("Hist√≥rico y Forecast (niveles log) -", varname))
  # A√±adir pron√≥stico
  lines(window(fc_ts, start = tsp(fc_ts)[1]), lwd = 2, lty = 2)
  # L√≠mites (aprox.) de confianza en niveles
  lines(ts(lev_hat_low[, varname],
           start = start(fc_ts), frequency = 4), lty = 3)
  lines(ts(lev_hat_high[, varname],
           start = start(fc_ts), frequency = 4), lty = 3)
  legend("topleft", bty = "n",
         legend = c("Hist√≥rico", "Pron√≥stico (media)", "Banda baja", "Banda alta"),
         lwd = c(2,2,1,1), lty = c(1,2,3,3))
  dev.off()
  cat("‚úÖ Gr√°fico guardado:", file_png, "\n")
}

# Elige algunas variables representativas para la clase:
for (vn in c("L_PP","L_PIB","L_GG","L_IF")) {
  plot_series_fc(vn, paste0("FC_LEVELS_", vn, ".png"))
}

# 7) (Opcional) Si quieres pron√≥stico en diferencias (Œîlog) tambi√©n en PNG:
plot_series_fc_diff <- function(varname, file_png) {
  while (!is.null(dev.list())) dev.off()
  png(file_png, width = 1400, height = 900, res = 150)
  par(mar = c(4,4,2,1))
  plot(dY_ts[, varname], type = "l", lwd = 2, xlab = "Trimestre", ylab = "Œî log",
       main = paste("Hist√≥rico Œîlog y Forecast -", varname))
  lines(ts(dhat_mean[, varname],
           start = c(2007 + (T)/4, (T %% 4) + 1), frequency = 4), lwd = 2, lty = 2)
  lines(ts(dhat_low[, varname],
           start = c(2007 + (T)/4, (T %% 4) + 1), frequency = 4), lty = 3)
  lines(ts(dhat_high[, varname],
           start = c(2007 + (T)/4, (T %% 4) + 1), frequency = 4), lty = 3)
  legend("topleft", bty = "n",
         legend = c("Œîlog hist√≥rico", "Œîlog pron√≥stico (media)", "Banda baja", "Banda alta"),
         lwd = c(2,2,1,1), lty = c(1,2,3,3))
  dev.off()
  cat("‚úÖ Gr√°fico guardado:", file_png, "\n")
}

for (vn in c("L_PP","L_PIB","L_GG","L_IF")) {
  plot_series_fc_diff(vn, paste0("FC_DIFF_", vn, ".png"))
}

cat("\n=== FORECAST listo: CSV + PNG exportados ===\n")

```
